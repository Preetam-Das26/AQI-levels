{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTJmsXnXQKbG"
   },
   "source": [
    "## Keras -- MLPs on Air Quality Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3833,
     "status": "ok",
     "timestamp": 1612493575297,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "2UILABPAQKbH"
   },
   "outputs": [],
   "source": [
    "# if you keras is not using tensorflow as backend set \"KERAS_BACKEND=tensorflow\" use this command\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist \n",
    "import seaborn as sns\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4730,
     "status": "ok",
     "timestamp": 1612493576402,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "TKmYKnibQKbQ",
    "outputId": "c2ecf97f-2d2e-45ad-f87e-e5c528a804a7"
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets \n",
    "#Read the Dataset\n",
    "data=pd.read_csv('MultiVariateAQI.csv')\n",
    "#Split the input and target sets\n",
    "X=pd.DataFrame(data.iloc[:,:-1])\n",
    "y=pd.DataFrame(data.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing: Normalize the Data\n",
    "scalerX = StandardScaler().fit(X)\n",
    "scalery = StandardScaler().fit(y)\n",
    "X_scale = scalerX.transform(X)\n",
    "y_scale = scalery.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Patterns into Train and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test= train_test_split(X_scale,y_scale,test_size=0.15,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4710,
     "status": "ok",
     "timestamp": 1612493576404,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "CCwnZae-QKbT",
    "outputId": "80f39883-0aea-4469-a17d-5c5018d58e70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples : 40963\n",
      "Number of training examples : 7229\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples :\", X_train.shape[0])\n",
    "print(\"Number of training examples :\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4705,
     "status": "ok",
     "timestamp": 1612493576405,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "BlotuCmoQKbW"
   },
   "outputs": [],
   "source": [
    "X_train = X_train\n",
    "X_test = X_test\n",
    "Y_train=y_train\n",
    "Y_test=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4667,
     "status": "ok",
     "timestamp": 1612493576407,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "qvuaHDk0QKbb",
    "outputId": "8e8b6457-a6f4-41f0-c7ae-1b7ea38996f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.42587862 -0.15177649 -0.39597468 -0.00556975 -0.01596386  0.12505375\n",
      " -0.40397641  0.32289297 -0.92855424 -0.2091982  -0.6533397  -0.31905745]\n"
     ]
    }
   ],
   "source": [
    "# An example data point\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4619,
     "status": "ok",
     "timestamp": 1612493576411,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "tLAGMubCQKbm"
   },
   "outputs": [],
   "source": [
    "# Import model and other libraries\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Activation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4615,
     "status": "ok",
     "timestamp": 1612493576412,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "I0s7jzhVQKbn"
   },
   "outputs": [],
   "source": [
    "# some model parameters\n",
    "\n",
    "output_dim = 1\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "batch_size = 128 \n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 9519,
     "status": "ok",
     "timestamp": 1612493581320,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "HdQg5wGDQKbr"
   },
   "outputs": [],
   "source": [
    "# start building a model\n",
    "model = Sequential()\n",
    "\n",
    "# The model needs to know what input shape it should expect. \n",
    "# For this reason, the first layer in a Sequential model \n",
    "# (and only the first, because following layers can do automatic shape inference)\n",
    "# needs to receive information about its input shape. \n",
    "# you can use input_shape and input_dim to pass the shape of input\n",
    "\n",
    "# output_dim represent the number of nodes need in that layer\n",
    "# here we have 10 nodes\n",
    "\n",
    "model.add(Dense(output_dim, input_dim=input_dim, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31267,
     "status": "ok",
     "timestamp": 1612494028473,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "EVA11VpmQKbt",
    "outputId": "762d393b-4c62-4ea1-c01f-4a8d34eadca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 3s 4ms/step - loss: 0.4473 - mse: 0.4473 - val_loss: 0.3456 - val_mse: 0.3456\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3454 - mse: 0.3454 - val_loss: 0.3455 - val_mse: 0.3455\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3454 - mse: 0.3454 - val_loss: 0.3447 - val_mse: 0.3447\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3453 - mse: 0.3453 - val_loss: 0.3461 - val_mse: 0.3461\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.3454 - mse: 0.3454 - val_loss: 0.3460 - val_mse: 0.3460\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3453 - mse: 0.3453 - val_loss: 0.3444 - val_mse: 0.3444\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3454 - mse: 0.3454 - val_loss: 0.3443 - val_mse: 0.3443\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3452 - mse: 0.3452 - val_loss: 0.3441 - val_mse: 0.3441\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3455 - mse: 0.3455 - val_loss: 0.3451 - val_mse: 0.3451\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.3453 - mse: 0.3453 - val_loss: 0.3452 - val_mse: 0.3452\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3454 - mse: 0.3454 - val_loss: 0.3446 - val_mse: 0.3446\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.3454 - mse: 0.3454 - val_loss: 0.3448 - val_mse: 0.3448\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3454 - mse: 0.3454 - val_loss: 0.3442 - val_mse: 0.3442\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3456 - mse: 0.3456 - val_loss: 0.3450 - val_mse: 0.3450\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3456 - mse: 0.3456 - val_loss: 0.3446 - val_mse: 0.3446\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.3454 - mse: 0.3454 - val_loss: 0.3443 - val_mse: 0.3443\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.3454 - mse: 0.3454 - val_loss: 0.3443 - val_mse: 0.3443\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3455 - mse: 0.3455 - val_loss: 0.3448 - val_mse: 0.3448\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3454 - mse: 0.3454 - val_loss: 0.3445 - val_mse: 0.3445\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.3451 - mse: 0.3451 - val_loss: 0.3446 - val_mse: 0.3446\n"
     ]
    }
   ],
   "source": [
    "# Before training a model, you need to configure the learning process, which is done via the compile method\n",
    "\n",
    "# It receives three arguments:\n",
    "# An optimizer. This could be the string identifier of an existing optimizer , https://keras.io/optimizers/\n",
    "# A loss function. This is the objective that the model will try to minimize., https://keras.io/losses/\n",
    "# A list of metrics. For any classification problem you will want to set this to metrics=['accuracy'].  https://keras.io/metrics/\n",
    "\n",
    "\n",
    "# Note: when using the categorical_crossentropy loss, your targets should be in categorical format \n",
    "# (e.g. if you have 10 classes, the target for each sample should be a 10-dimensional vector that is all-zeros except \n",
    "# for a 1 at the index corresponding to the class of the sample).\n",
    "\n",
    "# that is why we converted out labels into vectors\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Keras models are trained on Numpy arrays of input data and labels. \n",
    "# For training a model, you will typically use the  fit function\n",
    "\n",
    "# fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, \n",
    "# validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, \n",
    "# validation_steps=None)\n",
    "\n",
    "# fit() function Trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "\n",
    "# it returns A History object. Its History.history attribute is a record of training loss values and \n",
    "# metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).\n",
    "\n",
    "# https://github.com/openai/baselines/issues/20\n",
    "\n",
    "history = model.fit(X_train, Y_train, steps_per_epoch=500, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 1s 2ms/step\n",
      " Test RMSE : 277.52697288767126\n"
     ]
    }
   ],
   "source": [
    "# Predict using the obtained Model\n",
    "result_test = pd.DataFrame(model.predict(X_test))\n",
    "# De-Normalize the Predictions\n",
    "result_test = pd.DataFrame(scalery.inverse_transform(result_test),columns=['Predicted'])\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test,result_test))\n",
    "print(\" Test RMSE :\",rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eh4VWYrHQKbz"
   },
   "source": [
    " <h3>  MLP + Sigmoid activation + SGDOptimizer </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37214,
     "status": "ok",
     "timestamp": 1612493609067,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "7rzbngqHQKbz",
    "outputId": "4a695c3b-afab-47dc-b4e7-ee5579077d25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 512)               6656      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,449\n",
      "Trainable params: 72,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Multilayer perceptron\n",
    "\n",
    "model_sigmoid = Sequential()\n",
    "model_sigmoid.add(Dense(512, activation='sigmoid', input_shape=(input_dim,)))\n",
    "model_sigmoid.add(Dense(128, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(output_dim, activation='linear'))\n",
    "\n",
    "model_sigmoid.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65054,
     "status": "ok",
     "timestamp": 1612493636921,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "48vVImSpQKb5",
    "outputId": "141a28f1-a4e6-4ded-a69c-850f69bfe52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "321/321 [==============================] - 3s 7ms/step - loss: 0.6945 - mse: 0.6945 - val_loss: 0.4901 - val_mse: 0.4901\n",
      "Epoch 2/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.4251 - mse: 0.4251 - val_loss: 0.4295 - val_mse: 0.4295\n",
      "Epoch 3/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.3755 - mse: 0.3755 - val_loss: 0.3881 - val_mse: 0.3881\n",
      "Epoch 4/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.3541 - mse: 0.3541 - val_loss: 0.9275 - val_mse: 0.9275\n",
      "Epoch 5/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.3444 - mse: 0.3444 - val_loss: 0.4706 - val_mse: 0.4706\n",
      "Epoch 6/20\n",
      "321/321 [==============================] - 3s 9ms/step - loss: 0.3361 - mse: 0.3361 - val_loss: 0.8388 - val_mse: 0.8388\n",
      "Epoch 7/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.3329 - mse: 0.3329 - val_loss: 0.3902 - val_mse: 0.3902\n",
      "Epoch 8/20\n",
      "321/321 [==============================] - 3s 8ms/step - loss: 0.3288 - mse: 0.3288 - val_loss: 0.5000 - val_mse: 0.5000\n",
      "Epoch 9/20\n",
      "321/321 [==============================] - 2s 8ms/step - loss: 0.3260 - mse: 0.3260 - val_loss: 0.3950 - val_mse: 0.3950\n",
      "Epoch 10/20\n",
      "321/321 [==============================] - 2s 8ms/step - loss: 0.3225 - mse: 0.3225 - val_loss: 0.3215 - val_mse: 0.3215\n",
      "Epoch 11/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.3211 - mse: 0.3211 - val_loss: 0.3568 - val_mse: 0.3568\n",
      "Epoch 12/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.3179 - mse: 0.3179 - val_loss: 1.7396 - val_mse: 1.7396\n",
      "Epoch 13/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.3220 - mse: 0.3220 - val_loss: 0.3255 - val_mse: 0.3255\n",
      "Epoch 14/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.3146 - mse: 0.3146 - val_loss: 0.4501 - val_mse: 0.4501\n",
      "Epoch 15/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.3136 - mse: 0.3136 - val_loss: 0.3143 - val_mse: 0.3143\n",
      "Epoch 16/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.3121 - mse: 0.3121 - val_loss: 0.4419 - val_mse: 0.4419\n",
      "Epoch 17/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.3118 - mse: 0.3118 - val_loss: 0.3098 - val_mse: 0.3098\n",
      "Epoch 18/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.3088 - mse: 0.3088 - val_loss: 0.4676 - val_mse: 0.4676\n",
      "Epoch 19/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.3072 - mse: 0.3072 - val_loss: 0.3198 - val_mse: 0.3198\n",
      "Epoch 20/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.3059 - mse: 0.3059 - val_loss: 0.3765 - val_mse: 0.3765\n"
     ]
    }
   ],
   "source": [
    "model_sigmoid.compile(optimizer='sgd', loss='mse', metrics=['mse'])\n",
    "\n",
    "history = model_sigmoid.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 1s 3ms/step\n",
      " Test RMSE : 309.0289283537215\n"
     ]
    }
   ],
   "source": [
    "# Predict using the obtained Model\n",
    "result_test = pd.DataFrame(model_sigmoid.predict(X_test))\n",
    "# De-Normalize the Predictions\n",
    "result_test = pd.DataFrame(scalery.inverse_transform(result_test),columns=['Predicted'])\n",
    "# Computer the Root Mean Square Error on the Test Set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test,result_test))\n",
    "print(\" Test RMSE :\",rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExLv_CAeQKcA"
   },
   "source": [
    "<h2>MLP + Sigmoid activation + ADAM </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96525,
     "status": "ok",
     "timestamp": 1612493668441,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "w9BtnNGaQKcD",
    "outputId": "e28b5140-13fa-4fea-87b4-85782c638835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 512)               6656      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,449\n",
      "Trainable params: 72,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "321/321 [==============================] - 3s 7ms/step - loss: 0.4468 - mse: 0.4468 - val_loss: 0.3094 - val_mse: 0.3094\n",
      "Epoch 2/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2982 - mse: 0.2982 - val_loss: 0.3085 - val_mse: 0.3085\n",
      "Epoch 3/20\n",
      "321/321 [==============================] - 2s 8ms/step - loss: 0.2903 - mse: 0.2903 - val_loss: 0.2952 - val_mse: 0.2952\n",
      "Epoch 4/20\n",
      "321/321 [==============================] - 2s 8ms/step - loss: 0.2858 - mse: 0.2858 - val_loss: 0.2875 - val_mse: 0.2875\n",
      "Epoch 5/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.2840 - mse: 0.2840 - val_loss: 0.2838 - val_mse: 0.2838\n",
      "Epoch 6/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2787 - mse: 0.2787 - val_loss: 0.2925 - val_mse: 0.2925\n",
      "Epoch 7/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.2760 - mse: 0.2760 - val_loss: 0.2791 - val_mse: 0.2791\n",
      "Epoch 8/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.2698 - mse: 0.2698 - val_loss: 0.2708 - val_mse: 0.2708\n",
      "Epoch 9/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2663 - mse: 0.2663 - val_loss: 0.2697 - val_mse: 0.2697\n",
      "Epoch 10/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2602 - mse: 0.2602 - val_loss: 0.2927 - val_mse: 0.2927\n",
      "Epoch 11/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.2588 - mse: 0.2588 - val_loss: 0.2787 - val_mse: 0.2787\n",
      "Epoch 12/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2587 - mse: 0.2587 - val_loss: 0.2657 - val_mse: 0.2657\n",
      "Epoch 13/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2541 - mse: 0.2541 - val_loss: 0.2596 - val_mse: 0.2596\n",
      "Epoch 14/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2518 - mse: 0.2518 - val_loss: 0.2553 - val_mse: 0.2553\n",
      "Epoch 15/20\n",
      "321/321 [==============================] - 3s 8ms/step - loss: 0.2511 - mse: 0.2511 - val_loss: 0.2528 - val_mse: 0.2528\n",
      "Epoch 16/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.2483 - mse: 0.2483 - val_loss: 0.2561 - val_mse: 0.2561\n",
      "Epoch 17/20\n",
      "321/321 [==============================] - 3s 8ms/step - loss: 0.2499 - mse: 0.2499 - val_loss: 0.2602 - val_mse: 0.2602\n",
      "Epoch 18/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.2454 - mse: 0.2454 - val_loss: 0.2505 - val_mse: 0.2505\n",
      "Epoch 19/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.2433 - mse: 0.2433 - val_loss: 0.2491 - val_mse: 0.2491\n",
      "Epoch 20/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.2426 - mse: 0.2426 - val_loss: 0.2541 - val_mse: 0.2541\n"
     ]
    }
   ],
   "source": [
    "model_sigmoid = Sequential()\n",
    "model_sigmoid.add(Dense(512, activation='sigmoid', input_shape=(input_dim,)))\n",
    "model_sigmoid.add(Dense(128, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(output_dim, activation='linear'))\n",
    "\n",
    "model_sigmoid.summary()\n",
    "\n",
    "model_sigmoid.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "history = model_sigmoid.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 1s 3ms/step\n",
      " Test RMSE : 273.1480204629428\n"
     ]
    }
   ],
   "source": [
    "# Predict using the obtained Model\n",
    "result_test = pd.DataFrame(model_sigmoid.predict(X_test))\n",
    "# De-Normalize the Predictions\n",
    "result_test = pd.DataFrame(scalery.inverse_transform(result_test),columns=['Predicted'])\n",
    "# Computer the Root Mean Square Error on the Test Set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test,result_test))\n",
    "print(\" Test RMSE :\",rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRVrzqvSQKcL"
   },
   "source": [
    "<h2> MLP + ReLU +SGD </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98717,
     "status": "ok",
     "timestamp": 1612493670687,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "O8lG2jzmQKcM",
    "outputId": "c7797150-8e2e-4379-c2c7-5012284b2b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 512)               6656      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,449\n",
      "Trainable params: 72,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Multilayer perceptron\n",
    "\n",
    "# https://arxiv.org/pdf/1707.09725.pdf#page=95\n",
    "# for relu layers\n",
    "# If we sample weights from a normal distribution N(0,σ) we satisfy this condition with σ=√(2/(ni). \n",
    "# h1 =>  σ=√(2/(fan_in) = 0.062  => N(0,σ) = N(0,0.062)\n",
    "# h2 =>  σ=√(2/(fan_in)  = 0.125  => N(0,σ) = N(0,0.125)\n",
    "# out =>  σ=√(2/(fan_in+1) = 0.120  => N(0,σ) = N(0,0.120)\n",
    "\n",
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
    "model_relu.add(Dense(128, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "model_relu.add(Dense(output_dim, activation='linear'))\n",
    "\n",
    "model_relu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127397,
     "status": "ok",
     "timestamp": 1612493699373,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "QhtoviFKQKcP",
    "outputId": "74b44714-69a8-4019-b90b-ae8171e4cc09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "321/321 [==============================] - 3s 7ms/step - loss: 0.3041 - mse: 0.3041 - val_loss: 0.2648 - val_mse: 0.2648\n",
      "Epoch 2/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2498 - mse: 0.2498 - val_loss: 0.2502 - val_mse: 0.2502\n",
      "Epoch 3/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2393 - mse: 0.2393 - val_loss: 0.2442 - val_mse: 0.2442\n",
      "Epoch 4/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2328 - mse: 0.2328 - val_loss: 0.2438 - val_mse: 0.2438\n",
      "Epoch 5/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.2275 - mse: 0.2275 - val_loss: 0.2372 - val_mse: 0.2372\n",
      "Epoch 6/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2237 - mse: 0.2237 - val_loss: 0.2324 - val_mse: 0.2324\n",
      "Epoch 7/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2199 - mse: 0.2199 - val_loss: 0.2313 - val_mse: 0.2313\n",
      "Epoch 8/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2171 - mse: 0.2171 - val_loss: 0.2336 - val_mse: 0.2336\n",
      "Epoch 9/20\n",
      "321/321 [==============================] - 2s 5ms/step - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2298 - val_mse: 0.2298\n",
      "Epoch 10/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2118 - mse: 0.2118 - val_loss: 0.2330 - val_mse: 0.2330\n",
      "Epoch 11/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2100 - mse: 0.2100 - val_loss: 0.2255 - val_mse: 0.2255\n",
      "Epoch 12/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2078 - mse: 0.2078 - val_loss: 0.2283 - val_mse: 0.2283\n",
      "Epoch 13/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2060 - mse: 0.2060 - val_loss: 0.2176 - val_mse: 0.2176\n",
      "Epoch 14/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2040 - mse: 0.2040 - val_loss: 0.2200 - val_mse: 0.2200\n",
      "Epoch 15/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2026 - mse: 0.2026 - val_loss: 0.2461 - val_mse: 0.2461\n",
      "Epoch 16/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2015 - mse: 0.2015 - val_loss: 0.2105 - val_mse: 0.2105\n",
      "Epoch 17/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.1996 - mse: 0.1996 - val_loss: 0.3169 - val_mse: 0.3169\n",
      "Epoch 18/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.1988 - mse: 0.1988 - val_loss: 0.2120 - val_mse: 0.2120\n",
      "Epoch 19/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.1969 - mse: 0.1969 - val_loss: 1.0237 - val_mse: 1.0237\n",
      "Epoch 20/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.1998 - mse: 0.1998 - val_loss: 0.2222 - val_mse: 0.2222\n"
     ]
    }
   ],
   "source": [
    "model_relu.compile(optimizer='sgd', loss='mse', metrics=['mse'])\n",
    "\n",
    "history = model_relu.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 1s 3ms/step\n",
      " Test RMSE : 285.1563576533931\n"
     ]
    }
   ],
   "source": [
    "# Predict using the obtained Model\n",
    "result_test = pd.DataFrame(model_relu.predict(X_test))\n",
    "# De-Normalize the Predictions\n",
    "result_test = pd.DataFrame(scalery.inverse_transform(result_test),columns=['Predicted'])\n",
    "# Computer the Root Mean Square Error on the Test Set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test,result_test))\n",
    "print(\" Test RMSE :\",rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ccmfiVGQKcc"
   },
   "source": [
    "<h2> MLP + ReLU + ADAM </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159194,
     "status": "ok",
     "timestamp": 1612493731183,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "-CtwrinkQKcc",
    "outputId": "9e5dcacc-f771-4975-f919-233d9a08e379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 512)               6656      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,449\n",
      "Trainable params: 72,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "321/321 [==============================] - 3s 7ms/step - loss: 0.2611 - mse: 0.2611 - val_loss: 0.2318 - val_mse: 0.2318\n",
      "Epoch 2/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2221 - mse: 0.2221 - val_loss: 0.2219 - val_mse: 0.2219\n",
      "Epoch 3/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2196 - val_mse: 0.2196\n",
      "Epoch 4/20\n",
      "321/321 [==============================] - 3s 9ms/step - loss: 0.2039 - mse: 0.2039 - val_loss: 0.2213 - val_mse: 0.2213\n",
      "Epoch 5/20\n",
      "321/321 [==============================] - 3s 8ms/step - loss: 0.1980 - mse: 0.1980 - val_loss: 0.2098 - val_mse: 0.2098\n",
      "Epoch 6/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.1934 - mse: 0.1934 - val_loss: 0.2215 - val_mse: 0.2215\n",
      "Epoch 7/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1942 - val_mse: 0.1942\n",
      "Epoch 8/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.1854 - mse: 0.1854 - val_loss: 0.1995 - val_mse: 0.1995\n",
      "Epoch 9/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.1813 - mse: 0.1813 - val_loss: 0.1967 - val_mse: 0.1967\n",
      "Epoch 10/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.1751 - mse: 0.1751 - val_loss: 0.1944 - val_mse: 0.1944\n",
      "Epoch 11/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.1754 - mse: 0.1754 - val_loss: 0.1905 - val_mse: 0.1905\n",
      "Epoch 12/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.1700 - mse: 0.1700 - val_loss: 0.1831 - val_mse: 0.1831\n",
      "Epoch 13/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.1665 - mse: 0.1665 - val_loss: 0.1958 - val_mse: 0.1958\n",
      "Epoch 14/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.1655 - mse: 0.1655 - val_loss: 0.1828 - val_mse: 0.1828\n",
      "Epoch 15/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.1629 - mse: 0.1629 - val_loss: 0.1874 - val_mse: 0.1874\n",
      "Epoch 16/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.1586 - mse: 0.1586 - val_loss: 0.1803 - val_mse: 0.1803\n",
      "Epoch 17/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.1582 - mse: 0.1582 - val_loss: 0.1846 - val_mse: 0.1846\n",
      "Epoch 18/20\n",
      "321/321 [==============================] - 2s 8ms/step - loss: 0.1556 - mse: 0.1556 - val_loss: 0.1794 - val_mse: 0.1794\n",
      "Epoch 19/20\n",
      "321/321 [==============================] - 2s 7ms/step - loss: 0.1530 - mse: 0.1530 - val_loss: 0.1830 - val_mse: 0.1830\n",
      "Epoch 20/20\n",
      "321/321 [==============================] - 2s 6ms/step - loss: 0.1535 - mse: 0.1535 - val_loss: 0.1795 - val_mse: 0.1795\n"
     ]
    }
   ],
   "source": [
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
    "model_relu.add(Dense(128, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "model_relu.add(Dense(output_dim, activation='linear'))\n",
    "\n",
    "print(model_relu.summary())\n",
    "\n",
    "model_relu.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "history = model_relu.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 1s 2ms/step\n",
      " Test RMSE : 275.8483883588573\n"
     ]
    }
   ],
   "source": [
    "# Predict using the obtained Model\n",
    "result_test = pd.DataFrame(model_relu.predict(X_test))\n",
    "# De-Normalize the Predictions\n",
    "result_test = pd.DataFrame(scalery.inverse_transform(result_test),columns=['Predicted'])\n",
    "# Computer the Root Mean Square Error on the Test Set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test,result_test))\n",
    "print(\" Test RMSE :\",rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWYP8-3pQKct"
   },
   "source": [
    "<h2> 5. MLP + Dropout + AdamOptimizer </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 161338,
     "status": "aborted",
     "timestamp": 1612493733357,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "DJj0hu0-QKct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 512)               6656      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,449\n",
      "Trainable params: 72,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model_drop = Sequential()\n",
    "\n",
    "model_drop.add(Dense(512, activation='sigmoid', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(128, activation='sigmoid', kernel_initializer=RandomNormal(mean=0.0, stddev=0.55, seed=None)) )\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(output_dim, activation='linear'))\n",
    "\n",
    "\n",
    "model_drop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 161335,
     "status": "aborted",
     "timestamp": 1612493733358,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjpR94Niu_srJxsFT_3bp9vDfqrjd2Zx94jDQdMg=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "J5pc4W_9QKcw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "321/321 [==============================] - 4s 10ms/step - loss: 0.7724 - mse: 0.7724 - val_loss: 0.4004 - val_mse: 0.4004\n",
      "Epoch 2/20\n",
      "321/321 [==============================] - 3s 10ms/step - loss: 0.4672 - mse: 0.4672 - val_loss: 0.3482 - val_mse: 0.3482\n",
      "Epoch 3/20\n",
      "321/321 [==============================] - 3s 10ms/step - loss: 0.4146 - mse: 0.4146 - val_loss: 0.3364 - val_mse: 0.3364\n",
      "Epoch 4/20\n",
      "321/321 [==============================] - 3s 10ms/step - loss: 0.3821 - mse: 0.3821 - val_loss: 0.3274 - val_mse: 0.3274\n",
      "Epoch 5/20\n",
      "321/321 [==============================] - 3s 10ms/step - loss: 0.3644 - mse: 0.3644 - val_loss: 0.3269 - val_mse: 0.3269\n",
      "Epoch 6/20\n",
      "321/321 [==============================] - 3s 10ms/step - loss: 0.3512 - mse: 0.3512 - val_loss: 0.3209 - val_mse: 0.3209\n",
      "Epoch 7/20\n",
      "321/321 [==============================] - 3s 9ms/step - loss: 0.3446 - mse: 0.3446 - val_loss: 0.3210 - val_mse: 0.3210\n",
      "Epoch 8/20\n",
      "321/321 [==============================] - 3s 9ms/step - loss: 0.3363 - mse: 0.3363 - val_loss: 0.3118 - val_mse: 0.3118\n",
      "Epoch 9/20\n",
      "321/321 [==============================] - 3s 10ms/step - loss: 0.3327 - mse: 0.3327 - val_loss: 0.3084 - val_mse: 0.3084\n",
      "Epoch 10/20\n",
      "321/321 [==============================] - 4s 12ms/step - loss: 0.3280 - mse: 0.3280 - val_loss: 0.3072 - val_mse: 0.3072\n",
      "Epoch 11/20\n",
      "321/321 [==============================] - 4s 11ms/step - loss: 0.3236 - mse: 0.3236 - val_loss: 0.3049 - val_mse: 0.3049\n",
      "Epoch 12/20\n",
      "321/321 [==============================] - 3s 10ms/step - loss: 0.3216 - mse: 0.3216 - val_loss: 0.3083 - val_mse: 0.3083\n",
      "Epoch 13/20\n",
      "321/321 [==============================] - 3s 10ms/step - loss: 0.3193 - mse: 0.3193 - val_loss: 0.2968 - val_mse: 0.2968\n",
      "Epoch 14/20\n",
      "321/321 [==============================] - 3s 10ms/step - loss: 0.3164 - mse: 0.3164 - val_loss: 0.2969 - val_mse: 0.2969\n",
      "Epoch 15/20\n",
      "321/321 [==============================] - 3s 10ms/step - loss: 0.3124 - mse: 0.3124 - val_loss: 0.2991 - val_mse: 0.2991\n",
      "Epoch 16/20\n",
      "321/321 [==============================] - 3s 9ms/step - loss: 0.3125 - mse: 0.3125 - val_loss: 0.2933 - val_mse: 0.2933\n",
      "Epoch 17/20\n",
      "321/321 [==============================] - 3s 11ms/step - loss: 0.3109 - mse: 0.3109 - val_loss: 0.2947 - val_mse: 0.2947\n",
      "Epoch 18/20\n",
      "321/321 [==============================] - 3s 9ms/step - loss: 0.3073 - mse: 0.3073 - val_loss: 0.2914 - val_mse: 0.2914\n",
      "Epoch 19/20\n",
      "321/321 [==============================] - 3s 9ms/step - loss: 0.3076 - mse: 0.3076 - val_loss: 0.2907 - val_mse: 0.2907\n",
      "Epoch 20/20\n",
      "321/321 [==============================] - 3s 9ms/step - loss: 0.3063 - mse: 0.3063 - val_loss: 0.2885 - val_mse: 0.2885\n"
     ]
    }
   ],
   "source": [
    "model_drop.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 1s 3ms/step\n",
      " Test RMSE : 278.76706512948317\n"
     ]
    }
   ],
   "source": [
    "# Predict using the obtained Model\n",
    "result_test = pd.DataFrame(model_drop.predict(X_test))\n",
    "# De-Normalize the Predictions\n",
    "result_test = pd.DataFrame(scalery.inverse_transform(result_test),columns=['Predicted'])\n",
    "# Computer the Root Mean Square Error on the Test Set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test,result_test))\n",
    "print(\" Test RMSE :\",rmse_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keras_Mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

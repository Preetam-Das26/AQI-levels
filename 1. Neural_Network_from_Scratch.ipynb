{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Neural Network from scratch </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each row is a training example, each column is a feature  [f1, f2, f3]\n",
    "X=[0,0,1],[0,1,1],[1,0,1],[1,1,1]\n",
    "y=[0],[1],[1],[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing x and y with numpy\n",
    "import numpy as np\n",
    "X=np.array(([0,0,1],[0,1,1],[1,0,1],[1,1,1]), dtype=float)\n",
    "y=np.array(([0],[1],[1],[0]), dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Activation Function </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid  function\n",
    "def sigmoid(t):\n",
    "    '''This will return the sigmoid value of the function'''\n",
    "    return 1/(1+np.exp(-t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative sigmoid\n",
    "def sigmoid_derivative(d):\n",
    "    return d * (1 - d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class definition\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x,y):\n",
    "        self.input = x #initializing x\n",
    "        self.weights1= np.random.rand(self.input.shape[1],4) #initializing random weights\n",
    "        self.weights2 = np.random.rand(4,1)#considering we have 4 nodes in the hidden layer\n",
    "        self.y = y#initializing y\n",
    "        self.output = np. zeros(y.shape)#initializing the output\n",
    "        \n",
    "    def feedforward(self):\n",
    "        '''This will perform the forward propagation for the next 2 layers'''\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))#calcuation of w_T*X+b for layer1\n",
    "        self.layer2 = sigmoid(np.dot(self.layer1, self.weights2))#calcuation of w_T*X+b for layer2\n",
    "        return self.layer2\n",
    "        \n",
    "    def backprop(self,iter):\n",
    "        '''Back propagation of the final hidden layers to initial layers'''\n",
    "        derv_weights2 = np.dot(self.layer1.T, 2*(self.y -self.output)*sigmoid_derivative(self.output))#backpropagation of layer2\n",
    "        derv_weights1 = np.dot(self.input.T, np.dot(2*(self.y -self.output)*sigmoid_derivative(self.output), self.weights2.T)*sigmoid_derivative(self.layer1))\n",
    "    \n",
    "        self.weights1 += 1.0/iter * derv_weights1#updation of weight matrix of layer1\n",
    "        self.weights2 += 1.0/iter * derv_weights2#updation of weight matrix of layer2\n",
    "\n",
    "    def train(self, X, y,iter):\n",
    "        self.output = self.feedforward()#Forward Propagation\n",
    "        self.backprop(iter)#Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for iteration # 0\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.84783431]\n",
      " [0.90308169]\n",
      " [0.87245383]\n",
      " [0.91324168]]\n",
      "Loss: \n",
      "0.39462364061157723\n",
      "\n",
      "\n",
      "for iteration # 100\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.50203269]\n",
      " [0.53292958]\n",
      " [0.48506854]\n",
      " [0.51321791]]\n",
      "Loss: \n",
      "0.24968465745290835\n",
      "\n",
      "\n",
      "for iteration # 200\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49970052]\n",
      " [0.53028474]\n",
      " [0.48260163]\n",
      " [0.51034715]]\n",
      "Loss: \n",
      "0.2496220829474417\n",
      "\n",
      "\n",
      "for iteration # 300\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49890479]\n",
      " [0.52944503]\n",
      " [0.48181936]\n",
      " [0.5094452 ]]\n",
      "Loss: \n",
      "0.24959338976303758\n",
      "\n",
      "\n",
      "for iteration # 400\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49849357]\n",
      " [0.52904061]\n",
      " [0.48144223]\n",
      " [0.50901504]]\n",
      "Loss: \n",
      "0.24957426524145299\n",
      "\n",
      "\n",
      "for iteration # 500\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49823772]\n",
      " [0.52880588]\n",
      " [0.48122279]\n",
      " [0.50876777]]\n",
      "Loss: \n",
      "0.2495597901017287\n",
      "\n",
      "\n",
      "for iteration # 600\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49806066]\n",
      " [0.52865418]\n",
      " [0.48108047]\n",
      " [0.5086095 ]]\n",
      "Loss: \n",
      "0.24954810289810825\n",
      "\n",
      "\n",
      "for iteration # 700\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49792936]\n",
      " [0.52854904]\n",
      " [0.48098136]\n",
      " [0.50850088]]\n",
      "Loss: \n",
      "0.24953828624732705\n",
      "\n",
      "\n",
      "for iteration # 800\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49782715]\n",
      " [0.52847249]\n",
      " [0.4809088 ]\n",
      " [0.50842258]]\n",
      "Loss: \n",
      "0.24952981626243825\n",
      "\n",
      "\n",
      "for iteration # 900\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49774469]\n",
      " [0.52841469]\n",
      " [0.48085364]\n",
      " [0.50836407]]\n",
      "Loss: \n",
      "0.24952236407881453\n",
      "\n",
      "\n",
      "for iteration # 1000\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49767632]\n",
      " [0.5283698 ]\n",
      " [0.48081049]\n",
      " [0.50831911]]\n",
      "Loss: \n",
      "0.24951570911285456\n",
      "\n",
      "\n",
      "for iteration # 1100\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49761839]\n",
      " [0.52833416]\n",
      " [0.48077594]\n",
      " [0.50828381]]\n",
      "Loss: \n",
      "0.2495096959506306\n",
      "\n",
      "\n",
      "for iteration # 1200\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49756844]\n",
      " [0.52830536]\n",
      " [0.48074775]\n",
      " [0.5082556 ]]\n",
      "Loss: \n",
      "0.24950421084553998\n",
      "\n",
      "\n",
      "for iteration # 1300\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49752474]\n",
      " [0.52828173]\n",
      " [0.4807244 ]\n",
      " [0.50823275]]\n",
      "Loss: \n",
      "0.24949916797760444\n",
      "\n",
      "\n",
      "for iteration # 1400\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.49748605]\n",
      " [0.52826212]\n",
      " [0.48070479]\n",
      " [0.50821402]]\n",
      "Loss: \n",
      "0.24949450096638856\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=NeuralNetwork(X,y)\n",
    "for i in range(1500):\n",
    "    if i % 100 ==0:#For each 100 epochs output will come \n",
    "        print (\"for iteration # \" + str(i) + \"\\n\")\n",
    "        print (\"Input : \\n\" + str(X))\n",
    "        print (\"Actual Output: \\n\" + str(y))\n",
    "        print (\"Predicted Output: \\n\" + str(model.feedforward()))\n",
    "        print (\"Loss: \\n\" + str(np.mean(np.square(y - model.feedforward())))) # mean sum squared loss\n",
    "        print (\"\\n\")\n",
    "  \n",
    "    model.train(X, y,i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
